{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuIahsh1tXBS"
   },
   "source": [
    "# Background\n",
    "\n",
    "The objective of this notebook program is to find how similar two images are. This can be used to determine the derivative images from a source image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e9hQSKzxunS_"
   },
   "source": [
    "# Libraries\n",
    "---\n",
    "\n",
    "The following libraries are used in this program.\n",
    "\n",
    "*   **OpenCV:** OpenCV contains several packages for computer vision image recognition and processing.\n",
    "*   **Numpy:** provides packages for numeric processing.\n",
    "*   **Requests:** provides packages for processing making HTTP requests.\n",
    "*   **OpenAI:** provides packages for making calls to the OpenAI API library.\n",
    "\n",
    "Some libraries are not installed by default, hence manually installing them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bFZ_x4Q5e3Ui"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping opencv-python as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting opencv-contrib-python==3.4.2.17\n",
      "  Using cached opencv_contrib_python-3.4.2.17-cp37-cp37m-manylinux1_x86_64.whl (30.6 MB)\n",
      "Collecting numpy>=1.14.5 (from opencv-contrib-python==3.4.2.17)\n",
      "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "Installing collected packages: numpy, opencv-contrib-python\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "  Attempting uninstall: opencv-contrib-python\n",
      "    Found existing installation: opencv-contrib-python 3.4.2.17\n",
      "    Uninstalling opencv-contrib-python-3.4.2.17:\n",
      "      Successfully uninstalled opencv-contrib-python-3.4.2.17\n",
      "Successfully installed numpy-1.21.6 opencv-contrib-python-3.4.2.17\n"
     ]
    }
   ],
   "source": [
    "# We need to downgrade OpenCV as some none-free features are not available in the latest version\n",
    "# First uninstall OpenCV and then install the older version\n",
    "\n",
    "!pip uninstall opencv-python -y\n",
    "!pip install opencv-contrib-python==3.4.2.17 --force-reinstall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "zGdkArnlP01g"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import openai\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "from IPython.display import Image, display\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zC151CM7vOZD"
   },
   "source": [
    "# Data Sources\n",
    "\n",
    "We'll be generating images from Jupyter Notebook using DALL-E.\n",
    "\n",
    "This would require access to the OpenAI API. First login to the OpenAI portal and create a API key for accessing the various provided services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following creates a new OpenAPI instance using the provided API key.\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a text document, a prompt needs to be defined that would be used to 'seed' the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The wonderful world of AI\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this prompt, call the OpenAI create function to generate the image. In this example, we're generating a single image that matches the prompt, with a size of 1024x1024 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Image.create(\n",
    "    prompt=prompt,\n",
    "    n=1,\n",
    "    size=\"512x512\",\n",
    "    response_format=\"url\"\n",
    ")\n",
    "\n",
    "original_image_url = response['data'][0]['url']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAzuVrt7Py4z"
   },
   "source": [
    "Display the generated image in your Python code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(url=original_image_url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a list of related prompts that describe variations of the initial image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\"The future of AI\", \"The benefits of AI\", \"The wonders of AI\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the OpenAI API to generate images that match each prompt in the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variations_image_url = []\n",
    "\n",
    "for p in prompts:\n",
    "    response = openai.Image.create(\n",
    "        prompt=p,\n",
    "        n=1,\n",
    "        size=\"512x512\",\n",
    "        response_format=\"url\"\n",
    "    )\n",
    "\n",
    "    image_url = response[\"data\"][0][\"url\"]\n",
    "    variations_image_url.append(image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the generated images in your Python environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in variations_image_url:\n",
    "    display(Image(url=url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(url=variations_image_url[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nndO4cQKbDp8"
   },
   "outputs": [],
   "source": [
    "# download the image, convert it to a NumPy array, and then read\n",
    "def url_to_image(url):\n",
    "    resp = urlopen(url)\n",
    "    image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UE5IIa9HapvF"
   },
   "outputs": [],
   "source": [
    "# Download the original image\n",
    "original = url_to_image(original_image_url)\n",
    "plt.imshow(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the original image\n",
    "variation1 = url_to_image(variations_image_url[0])\n",
    "plt.imshow(variation1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GBsvy5m9wh3G"
   },
   "source": [
    "# Image Processing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmP6Rwh-QSPc"
   },
   "source": [
    "We need to determine the similarity of two images. \n",
    "\n",
    "Through feature detection and feature matching, we can find derived images which are similar to the source image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIG1m61S5voH"
   },
   "source": [
    "Here an approach called Scale Invariant Feature Transform (SIFT) is used to extract keypoints and compute its descriptors.\n",
    "\n",
    " - Keypoints are locations in the image that are determined based on measures of their stability.\n",
    " - Descriptors are local image gradients at selected scale and rotation that describe each keypoint region.\n",
    "\n",
    "SIFT is based on a paper by D.Lowe, University of British Columbia in 2004. A tutorial on SIFT is given at https://docs.opencv.org/master/da/df5/tutorial_py_sift_intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqmeqCFbQhG9"
   },
   "outputs": [],
   "source": [
    "# Construct a SIFT object\n",
    "sift = cv2.xfeatures2d.SIFT_create()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKC8Y5fh-eUU"
   },
   "source": [
    "sift.detect() function finds the keypoint in the images.\n",
    "sift.compute() function computes the descriptors from the keypoints we have found.\n",
    "OR\n",
    "sift.detectAndCompute() function finds both keypoints and descriptors in a single step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pkI05kkueeCY"
   },
   "outputs": [],
   "source": [
    "# Detect key points and descriptors both both images\n",
    "kp_1, desc_1 = sift.detectAndCompute(url_to_image(original_image_url), None)\n",
    "kp_2, desc_2 = sift.detectAndCompute(url_to_image(variations_image_url[0]), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oV1wBQxT-5v0"
   },
   "source": [
    "OpenCV also provides cv.drawKeyPoints() function which draws the small circles on the locations of keypoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmCpu8Pumf5j"
   },
   "outputs": [],
   "source": [
    "# drawKeypoints function is used to draw keypoints\n",
    "output_image=cv2.drawKeypoints(original, kp_1, 0, (0, 0, 255), flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# displaying the image with keypoints as the output on the screen\n",
    "  \n",
    "plt.imshow(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mwUnjifk7_oR"
   },
   "outputs": [],
   "source": [
    "# drawKeypoints function is used to draw keypoints\n",
    "output_image=cv2.drawKeypoints(variation1, kp_1, 0, (0, 0, 255), flags=cv2.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "\n",
    "# displaying the image with keypoints as the output on the screen\n",
    "  \n",
    "plt.imshow(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QB-gNUcyQnwp"
   },
   "outputs": [],
   "source": [
    "# Load FlannBasedMatcher which is the method used to find the matches between the descriptors of both the images.\n",
    "index_params = dict(algorithm=0, trees=5)\n",
    "search_params = dict()\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
    "\n",
    "# Find the matches between the 2 images, which is stored in the array  ‘matches’.\n",
    "# The array will contain all possible matches, so many false matches as well.\n",
    "matches = flann.knnMatch(desc_1, desc_2, k=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "getD8MjjQqJi"
   },
   "source": [
    "Apply the ratio test to select only the good matches. The quality of a match is define by the distance. The distance is a number, and the lower this number is, the more similar the features are.\n",
    "\n",
    "By applying the ratio test we can decide to take only the matches with lower distance, so higher quality.\n",
    " - Decreasing the ratio value will get high quality matches but fewer matches.\n",
    " - Increasing the ratio value will get more matches but many false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sa5coEaGQtM0"
   },
   "outputs": [],
   "source": [
    "good_points = []\n",
    "ratio = 0.8\n",
    "\n",
    "for m, n in matches:\n",
    "    if m.distance < ratio*n.distance:\n",
    "        good_points.append(m)\n",
    "\n",
    "# Find the number of good matches found\n",
    "print(len(good_points))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRt4HqOuMKtk"
   },
   "source": [
    "We can see the found matches of keypoints from both two images. Here the parameters are,\n",
    " - img1 – First source image.\n",
    " - keypoints1 – Keypoints from the first source image.\n",
    " - img2 – Second source image.\n",
    " - keypoints2 – Keypoints from the second source image.\n",
    " - matches1to2 – Matches from the first image to the second one, which means that keypoints1[i] has a corresponding point in keypoints2[matches[i]] ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l1RWSU2ELAu9"
   },
   "outputs": [],
   "source": [
    "result = cv2.drawMatches(original, kp_1, variation1, kp_2, good_points, None)\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNtxOSARJ2cD7iVxU8xz7Cy",
   "include_colab_link": true,
   "name": "image_similarity.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
