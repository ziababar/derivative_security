{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gBEUj0wzWt7X"
   },
   "source": [
    "# Background\n",
    "---\n",
    "\n",
    "The objective of this notebook program is to find how similar two documents are. This can be used to determine the derivative documents from a source document.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zLES_4eKGyjp"
   },
   "source": [
    "# Libraries\n",
    "---\n",
    "\n",
    "The following libraries are used in this program.\n",
    "\n",
    "*   **Natural language toolkit:** NLTK contains text processing libraries for tokenization, parsing, classification, stemming, tagging and semantic reasoning.\n",
    "*   **Gensim:** provides packages for processing texts, working with word vector models.\n",
    "*   **Numpy:** provides packages for numeric processing.\n",
    "*   **Requests:** provides packages for processing making HTTP requests.\n",
    "*   **OpenAI:** provides packages for making calls to the OpenAI API library.\n",
    "\n",
    "Some libraries are not installed by default, hence manually installing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install nltk\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_-FnFlOEROOG",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import gensim\n",
    "import nltk\n",
    "import numpy\n",
    "import requests\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-LrFc_PDRUCT",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize # Word Tokenizer\n",
    "from nltk.tokenize import sent_tokenize # Sentence Tokenizer\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ScKOVn2-G8_E"
   },
   "source": [
    "# Data Sources\n",
    "---\n",
    "\n",
    "We'll be generating text documents from Jupyter Notebook using ChatGPT.\n",
    "\n",
    "This would require access to the OpenAI API. First login to the OpenAI portal and create a API key for accessing the various provided services.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lapzvT1ORni0",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# The following creates a new OpenAPI instance using the provided API key.\n",
    "openai.api_key = \"api_key\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a text document, a prompt needs to be defined that would be used to 'seed' the response.\n",
    "\n",
    "Using this prompt, call the OpenAI create function to generate the text, and save the output to a file.\n",
    "\n",
    "In this example, we are using the Davinci engine, which is the most advanced model available from OpenAI. The max_tokens parameter controls the length of the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"What are the benefits of Artificial Intelligence\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this prompt, call the OpenAI create function to generate the text, and save the output to a file.\n",
    "\n",
    "In this example, we are using the Davinci engine, which is the most advanced model available from OpenAI. The max_tokens parameter controls the length of the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\", prompt=prompt, max_tokens=1000\n",
    ")\n",
    "\n",
    "original_text = response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the output to a file by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/text/original_text.txt\", \"w\") as f:\n",
    "    f.write(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate variations of a text document using ChatGPT, you can use a process called \"text rewriting\".\n",
    "\n",
    "In this example, we're using the Davinci engine again, and we're asking the model to rewrite the sentence that includes the original text. The generated text will be saved in the variation_text variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Rewrite this sentence: {original_text}\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\", prompt=prompt, max_tokens=900\n",
    ")\n",
    "\n",
    "variation_text1 = response.choices[0].text.strip()\n",
    "\n",
    "with open(\"data/text/variation_text1.txt\", \"w\") as f:\n",
    "    f.write(variation_text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the above two more times to obtain a total of three variation texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Rewrite this sentence: {original_text}\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    engine=\"davinci\", prompt=prompt, max_tokens=900\n",
    ")\n",
    "\n",
    "variation_text2 = response.choices[0].text.strip()\n",
    "\n",
    "with open(\"data/text/variation_text2.txt\", \"w\") as f:\n",
    "    f.write(variation_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that indeed that OpenAI generated text, print out the lengths of each of the generated text strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Size of original text: \", len(original_text))\n",
    "print(\"Size of variation1 text: \", len(variation_text1))\n",
    "print(\"Size of variation2 text: \", len(variation_text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d4pXI8GHHb7P"
   },
   "source": [
    "# Document Parsing\n",
    "---\n",
    "We need to parse the document and extract all the words from the document. This is done through a two step process.\n",
    "1. Open the document and get all the sentences through the sent_tokenize() function.\n",
    "2. For each sentence, get all the words in that sentence using the word_tokenize() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jJhNFapNIDzK",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Empty array that contains all the sentences\n",
    "sent_array = []\n",
    "\n",
    "sent_tokens = sent_tokenize(original_text)\n",
    "for line in sent_tokens:\n",
    "    sent_array.append(line)\n",
    "\n",
    "print(\"Number of sentences: \", len(sent_array))\n",
    "print(sent_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PtS81giStyHG",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "word_array = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in sent_array]\n",
    "print(word_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SYwc5uhm6FbV"
   },
   "source": [
    "Gensim requires the words (aka tokens) be converted to unique ids before it can process them.\n",
    "\n",
    "Create a Dictionary object that maps each word to a unique id. Let's convert our sentences to a [list of words] and pass it to the corpora.Dictionary() object. A dictionary maps every word to a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qG69oBPR6GPV",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(word_array)\n",
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wQHZYizEHgJY"
   },
   "source": [
    "### Step 1 - Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-26OkEAFRufF"
   },
   "source": [
    "Create a Corpus. A ‘corpus’ is typically a ‘collection of documents as a bag of words’.\n",
    "\n",
    "The corpus is an object that contains the word id and its frequency in each document.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LAl236KY6dZs",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Create a corpus and pass the tokenized list of words to the Dictionary.doc2bow()\n",
    "# Here bow stands for bag-of-words\n",
    "corpus_source = [dictionary.doc2bow(word) for word in word_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "higIr2xw6r6k",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(corpus_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyiKRpSaIask"
   },
   "source": [
    "### Step 2 - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZVR8_cD6iwn"
   },
   "source": [
    "Term Frequency – Inverse Document Frequency(TF-IDF) is also a bag-of-words model but unlike the regular corpus, TFIDF down weights tokens (words) that appears frequently across documents.\n",
    "\n",
    "TF-IDF is calculated by multiplying a local component (TF) with a global component (IDF) and optionally normalizing the result to unit length.\n",
    "\n",
    "Term frequency is how often the word shows up in the document and inverse document frequency scales the value by how rare the word is in the corpus. In simple terms, words that occur more frequently across the documents get smaller weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxDawqPGSoMN",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_source = gensim.models.TfidfModel(corpus_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TP9yMkDn6o0S"
   },
   "source": [
    "For example, the word ‘the’ occurs in multiple documents so it weighted down. The word ‘this’ and 'is' appearing in all three documents so removed altogether."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UXnIhVTrwQQ3",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "for doc in tfidf_source[corpus_source]:\n",
    "    print([[dictionary[id], numpy.around(freq, decimals=2)] for id, freq in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "77yWk1syx2Q_"
   },
   "source": [
    "### Step 3 - Parse other documents too\n",
    "Perform the same processing for the other two documents as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QChVVKSx1h4",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sent_array = []\n",
    "sent_tokens = sent_tokenize(variation_text1)\n",
    "for line in sent_tokens:\n",
    "    sent_array.append(line)\n",
    "\n",
    "word_array = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in sent_array]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(word_array)\n",
    "corpus_variation1 = [dictionary.doc2bow(word) for word in word_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G443UFM1yu7y",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "sent_array = []\n",
    "sent_tokens = sent_tokenize(variation_text2)\n",
    "for line in sent_tokens:\n",
    "    sent_array.append(line)\n",
    "\n",
    "word_array = [[w.lower() for w in word_tokenize(text)] \n",
    "            for text in sent_array]\n",
    "\n",
    "dictionary = gensim.corpora.Dictionary(word_array)\n",
    "corpus_variation2 = [dictionary.doc2bow(word) for word in word_array]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1OtOUo_ygwc",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(corpus_source)\n",
    "print(corpus_variation1)\n",
    "print(corpus_variation2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "49GcziAzIflb"
   },
   "source": [
    "# Determining Document Similarity\n",
    "---\n",
    "Now, we are going to create similarity object using cosine similarity. Cosine similarity is a standard measure in Vector Space Modeling to determine the similarity of two vectors.\n",
    "\n",
    "The main class is Similarity, which builds an index for a given set of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQKAOPsWSqs8",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Build the index\n",
    "sims = gensim.similarities.MatrixSimilarity(tfidf_source[corpus_source])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHvtllxKJKSO"
   },
   "source": [
    "To determine similarity between two documents, we perform two steps. First we get a query document based on the document that needs to be compared, and this is then used to get the similarity index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jaNERDHZTXWG",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# obtain a similarity query against the source corpus\n",
    "query_variation1 = tfidf_source[corpus_variation1]\n",
    "query_variation2 = tfidf_source[corpus_variation2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the similarity index for each of the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zlGNs17Z3eUh",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(numpy.around(sims[query_variation1], decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4V7F2QJK3e-X",
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "print(numpy.around(sims[query_variation2], decimals=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the results of the similarity index, it can be determined which variation is closed to the original text."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "document-similarity.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
